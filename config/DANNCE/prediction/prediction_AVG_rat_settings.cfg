# INPUT_WIDTH DEPRECATED. WILL REMOVE. For now, must match the cropped size of the input images
INPUT_WIDTH: 1280

# INPUT_HEIGHT DEPRECATED. WILL REMOVE. For now, must match the cropped size of the input images
INPUT_HEIGHT: 1024

# OUTPUT_WIDTH DEPRECATED. WILL REMOVE. For now, must match the cropped size of the input images
OUTPUT_WIDTH: 1280

# OUTPUT_HEIGHT DEPRECATED. WILL REMOVE. For now, must match the cropped size of the input images
OUTPUT_HEIGHT: 1024

# How to crop the input images. The U-Net expects each dimension size to be a multiple of 32.
CROP_HEIGHT: (0, 1024)
CROP_WIDTH: (20, 1300)

# Number of channels for each input image (e.g. RGB == 3)
N_CHANNELS_IN: 3

# Number of network output channels.
N_CHANNELS_OUT: 20

# BBOX_WIDTH DEPRECATED. WILL REMOVE. For now, must match the cropped size of the input images
BBOX_WIDTH: 1280

# BBOX_HEIGHT DEPRECATED. WILL REMOVE. For now, must match the cropped size of the input images
BBOX_HEIGHT: 1024

# Batch size -- default 1
BATCH_SIZE: 1

# WORKERS DEPRECATED. WILL REMOVE. Multi-processing is unstable when working with multiple videos
WORKERS: 2

# MAX_QUEUE_SIZE DEPRECATED. WILL REMOVE. Multi-processing is unstable when working with multiple videos
MAX_QUEUE_SIZE: 10

# DANNCE training option. Sets the size of the 3D Guassians (in mm) used as labels for the MAX models
SIGMA: 10

# DANNCE training option. Sets the number of epochs during training
EPOCHS: 5

# DANNCE training option. Sets the verbosity of training output
VERBOSE: 1

# TILEFAC DEPRECATED. WILL REMOVE.
TILEFAC: 1

# Degree of downsampling applied to image input. Default 1, other values untested.
DOWNFAC: 1

# During prediction, OUT_MODE should be set to 'coordinates'. During training, OUT_MODE should be set to '3dprob' for MAX and 'coordinates' for AVG. 
OUT_MODE: coordinates

# DANNCE training option. Loss function to be used. Default MSE.
loss: mean_squared_error

# DANNCE training option. Learning rate for the Adam optimizer. Default 1e-3.
lr: 1e-3

# path to the pre-trained weights file used for making predictions (or for fine-tuning from)
weightsfile: ./weights/weights.rat.AVG.hdf5

# name of the network architecture (see nets.py)
net: nets.unet3d_big_tiedfirstlayer_expectedvalue
batch_norm: False
instance_norm: True

# If true, each camera's video directory contains only the video files. If false, each camera's video directory contains an additional subdirectory, which then contains the video files
vid_dir_flag: True

# DANNCE training. Metric to be monitored in addition to loss
metric: mse

# Limits (in mm) to 3D volumes anchored on subject
VMIN: -120
VMAX: 120
# Number of voxels along each spatial dimension
NVOX: 64

# Interpolation mode.
INTERP: nearest

# If DEPTH is true, will append depth information when sampling images. Particularly useful when using just 1 cameras.
DEPTH: False

IMMODE: 'vid'

# DANNCE training option. Whetehr to turn on rotation augmentation during training
ROTATE: False

# Whether to apply lens distortion during sampling. Default True
DISTORT: True

# If true, intializes an "AVG" version of the network (i.e. final spatial expected value output layer). If false, "MAX" version
EXPVAL: True

# COM finder output confidence scores less than this threshodl will be discarded
comthresh: 0

# If True, will weight the COM estimate in each camera by its confidence score
weighted: False

# Method or combining 3D COMs across camera pairs. Options: 'median', 'mean'
com_method: 'median'

# Dictates whether or not to randomly shuffle the camera order when processing volumes. Options: None, 'random'
CHANNEL_COMBO: None